{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Transcript from pandas to Spark\n",
    "\n",
    "The Notebook transcripts the methods applied in pandas for the feature\n",
    "engineering generation into a Spark Dataframe and methods applied to result\n",
    "into the same, or similar outcome.\n",
    "\n",
    "At the end of the notebook the original df result will be compared with the\n",
    "spark functions outcome to compare and accept if the resulting functions are\n",
    "sufficient to accept them as a valid result."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import rank\n",
    "from pyspark.sql.functions import monotonically_increasing_id, current_date, \\\n",
    "    when, lit, col, months_between, floor\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Credit Features Processing\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw_data/dataset_credit_risk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_func = spark.read.csv(\"../data/raw_data/dataset_credit_risk.csv\",\n",
    "                         header=True,\n",
    "                         sep=',',\n",
    "                         inferSchema=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Sort and cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(by=[\"id\", \"loan_date\"])\n",
    "df = df.reset_index(drop=True)\n",
    "df[\"loan_date\"] = pd.to_datetime(df.loan_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# spark\n",
    "def order_by_id_and_loan_date(data_frame):\n",
    "    data_frame = data_frame.orderBy(\"id\", \"loan_date\")\n",
    "    # Index only to compare with pandas\n",
    "    data_frame = data_frame.withColumn(\"index\",\n",
    "                                       monotonically_increasing_id())\n",
    "    return data_frame\n",
    "\n",
    "def cast_dates_to_datetime(data_frame):\n",
    "    # loan_date\n",
    "    data_frame = data_frame.withColumn('loan_date',\n",
    "                                       data_frame['loan_date'].cast('date'))\n",
    "    data_frame = data_frame.withColumn('loan_date',\n",
    "                                       when(col(\"loan_date\")\n",
    "                                            <= current_date()+1,\n",
    "                                            col(\"loan_date\")))\n",
    "    #birthday\n",
    "    data_frame = data_frame.withColumn('birthday',\n",
    "                                       data_frame['birthday'].cast('date'))\n",
    "    data_frame = data_frame.withColumn('birthday',\n",
    "                                       when(col(\"birthday\")\n",
    "                                            <= current_date()+1,\n",
    "                                            col(\"birthday\")))\n",
    "    # job_start_date\n",
    "    data_frame = data_frame.withColumn('job_start_date',\n",
    "                                       data_frame['job_start_date'].cast('date'))\n",
    "    data_frame = data_frame.withColumn('job_start_date',\n",
    "                                       when(col(\"job_start_date\")\n",
    "                                            <= current_date()+1,\n",
    "                                            col(\"job_start_date\")))\n",
    "    return data_frame\n",
    "\n",
    "df_func = order_by_id_and_loan_date(df_func)\n",
    "df_func = cast_dates_to_datetime(df_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Feature nb_previous_loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_grouped = df.groupby(\"id\")\n",
    "df[\"nb_previous_loans\"] = df_grouped[\"loan_date\"].rank(method=\"first\") - 1\n",
    "df[\"nb_previous_loans\"] = df[\"nb_previous_loans\"].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_nb_previous_loans(data_frame):\n",
    "    window = Window.partitionBy(\"id\").orderBy(\"loan_date\")\n",
    "    data_frame = data_frame.withColumn(\"nb_previous_loans\",\n",
    "                                       rank().over(window) -1)\n",
    "    return data_frame\n",
    "df_func = generate_nb_previous_loans(df_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Feature avg_amount_loans_previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def avg_amount_loans_prev(df):\n",
    "    avg = pd.Series(index=df.index)\n",
    "    for i in df.index:\n",
    "        df_aux = df.loc[df.loan_date < df.loan_date.loc[i], :]\n",
    "        avg.at[i] = df_aux.loan_amount.mean()\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuel.rojo/.pyenv/versions/ml_technical_challenge/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/samuel.rojo/.pyenv/versions/ml_technical_challenge/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 2s, sys: 21.4 s, total: 10min 23s\n",
      "Wall time: 10min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time  \n",
    "avg_amount_loans_previous = pd.Series()\n",
    "# the following cycle is the one that takes forever if we try to compute it for the whole dataset\n",
    "for user in df.id.unique():\n",
    "    df_user = df.loc[df.id == user, :]\n",
    "    avg_amount_loans_previous = avg_amount_loans_previous.append(avg_amount_loans_prev(df_user))\n",
    "\n",
    "df[\"avg_amount_loans_previous\"] = avg_amount_loans_previous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.11 ms, sys: 5.49 ms, total: 10.6 ms\n",
      "Wall time: 152 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def generate_avg_amount_loans_previous(data_frame):\n",
    "    window = Window.partitionBy(\"id\"). \\\n",
    "        rowsBetween(Window.unboundedPreceding, -1)\n",
    "\n",
    "    data_frame = data_frame.sort(f.asc('loan_date')) \\\n",
    "        .withColumn(\"avg_amount_loans_previous\",\n",
    "                    f.mean('loan_amount').over(window))\n",
    "    return data_frame\n",
    "\n",
    "df_func = generate_avg_amount_loans_previous(df_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['birthday'] = pd.to_datetime(df['birthday'], errors='coerce')\n",
    "df['age'] = (pd.to_datetime('today').normalize() -\n",
    "             df['birthday']).dt.days // 365\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [],
   "source": [
    "def compute_age_features(data_frame):\n",
    "    data_frame = data_frame.withColumn(\"age\",\n",
    "                          floor(months_between(current_date(),\n",
    "                                               col(\"birthday\"))/lit(12))\n",
    "                          .cast('integer'))\n",
    "    return data_frame\n",
    "\n",
    "df_func = compute_age_features(df_func)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature years_on_the_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['job_start_date'] = pd.to_datetime(df['job_start_date'], errors='coerce')\n",
    "df['years_on_the_job'] = (pd.to_datetime('today').normalize() -\n",
    "                          df['job_start_date']).dt.days // 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_years_on_the_job(data_frame):\n",
    "    data_frame = data_frame.withColumn(\"years_on_the_job\",\n",
    "                          floor(months_between(current_date(),\n",
    "                                               col(\"job_start_date\"))/lit(12))\n",
    "                          .cast('integer'))\n",
    "    return data_frame\n",
    "\n",
    "df_func = compute_years_on_the_job(df_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature flag_own_car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['flag_own_car'] = df.flag_own_car.apply(lambda x : 0 if x == 'N' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_feature_own_car_flag(data_frame):\n",
    "    data_frame = data_frame.withColumn('flag_own_car',\n",
    "                                       when(col(\"flag_own_car\") == 'N',\n",
    "                                            lit(0)).otherwise(1))\n",
    "    return data_frame\n",
    "\n",
    "df_func = add_feature_own_car_flag(df_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select subset of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df[['id',\n",
    "         'age',\n",
    "         'years_on_the_job',\n",
    "         'nb_previous_loans',\n",
    "         'avg_amount_loans_previous',\n",
    "         'flag_own_car', 'status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def credit_fe_columns_subset(data_frame):\n",
    "    data_frame = data_frame.select('id',\n",
    "                             'age',\n",
    "                             'years_on_the_job',\n",
    "                             'nb_previous_loans',\n",
    "                             'avg_amount_loans_previous',\n",
    "                             'flag_own_car',\n",
    "                             'status')\n",
    "    return data_frame\n",
    "\n",
    "df_func = credit_fe_columns_subset(df_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare Results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_copy = df.copy()\n",
    "# df = df_copy.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 322,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Order both dataset to do a 1:1 comparinson"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "outputs": [],
   "source": [
    "df_func = df_func.orderBy('index') # Index only to compare with pd.Dataframe\n",
    "df = df.sort_index() # pd.Dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_test = df_func.toPandas() # Transform PySpark dataframe into pd.Dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 777715 entries, 0 to 777714\n",
      "Data columns (total 7 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   id                         777715 non-null  object \n",
      " 1   age                        777715 non-null  int32  \n",
      " 2   years_on_the_job           649743 non-null  float64\n",
      " 3   nb_previous_loans          777715 non-null  int32  \n",
      " 4   avg_amount_loans_previous  741258 non-null  float64\n",
      " 5   flag_own_car               777715 non-null  int32  \n",
      " 6   status                     777715 non-null  object \n",
      "dtypes: float64(2), int32(3), object(2)\n",
      "memory usage: 32.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_test.info(verbose=True) # PySpark convert to pandas Resulting schema"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 777715 entries, 0 to 777714\n",
      "Data columns (total 7 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   id                         777715 non-null  int64  \n",
      " 1   age                        777715 non-null  int64  \n",
      " 2   years_on_the_job           649743 non-null  float64\n",
      " 3   nb_previous_loans          777715 non-null  int64  \n",
      " 4   avg_amount_loans_previous  740750 non-null  float64\n",
      " 5   flag_own_car               777715 non-null  int64  \n",
      " 6   status                     777715 non-null  int64  \n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 41.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=True) # pd.Dataframe resulting schema"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Due to the differences presented in the schemas, the pyspark dataframe will be\n",
    "casted into the schema of the pd.Dataframe in order to reproduce the results\n",
    "and make them comparable 1:1. This is decided after seeing a comparinson\n",
    "with no nulls in both outcomes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "outputs": [],
   "source": [
    "df_test[\"id\"] = df_test[\"id\"].astype(int)\n",
    "df_test[\"age\"] = df_test[\"age\"].astype(int)\n",
    "df_test[\"flag_own_car\"] = df_test[\"flag_own_car\"].astype(int)\n",
    "df_test[\"nb_previous_loans\"] = df_test[\"nb_previous_loans\"].astype(int)\n",
    "df_test[\"status\"] = df_test[\"status\"].astype(int)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cast float64 fields and round to same data type and same number of decimals\n",
    "to avoid resolution misscomparison."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 777715 entries, 0 to 777714\n",
      "Data columns (total 7 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   id                         777715 non-null  int64  \n",
      " 1   age                        777715 non-null  int64  \n",
      " 2   years_on_the_job           649743 non-null  float64\n",
      " 3   nb_previous_loans          777715 non-null  int64  \n",
      " 4   avg_amount_loans_previous  741258 non-null  float64\n",
      " 5   flag_own_car               777715 non-null  int64  \n",
      " 6   status                     777715 non-null  int64  \n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 41.5 MB\n"
     ]
    }
   ],
   "source": [
    "# Round years to zero decimals\n",
    "df_test[\"years_on_the_job\"] = \\\n",
    "    df_test[\"years_on_the_job\"].astype('float64').round(0)\n",
    "df[\"years_on_the_job\"] = df[\"years_on_the_job\"].round(0)\n",
    "\n",
    "# Round float fields to 2 decimals\n",
    "df_test[\"avg_amount_loans_previous\"] = \\\n",
    "    df_test[\"avg_amount_loans_previous\"].astype('float64').round(2)\n",
    "df[\"avg_amount_loans_previous\"] = df[\"avg_amount_loans_previous\"].round(2)\n",
    "\n",
    "df_test.info(verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Assertion of a 1:1 comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outcomes are different than expected:  False\n",
      "Are the shapes of both datasets the same?: True\n"
     ]
    }
   ],
   "source": [
    "print(\"The outcomes are different than expected: \", df_test.equals(df))\n",
    "print(\"Are the shapes of both datasets the same?:\", (df.shape==df_test.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Because of side effects of the python floor division and traditional round\n",
    "function in the years calculated in pandas the fields with those values will\n",
    "be dropped after seing how many records have differences between both\n",
    "dataframes and adress those fields are the discrepancy causes, just to follow\n",
    "the asumption that the round vs floor libraries are the cause.\n",
    "\n",
    "Disclaimer: The floor function was denoted bevause the age of a person has to\n",
    "be quantizied after the birthday and not after 6 months or any other arbitrary\n",
    "value for the months."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def test_differences(df1, df2):\n",
    "    different_records_df=pd.concat([df1,df2]).drop_duplicates(keep=False)\n",
    "    print(\"Head of df of not matching records\")\n",
    "    print(different_records_df.sort_index().head(100))\n",
    "\n",
    "    # Both different records are kept for the same row\n",
    "    different_records = different_records_df.shape[0]/2\n",
    "    total_expected_records = df.shape[0]\n",
    "    difference_percentage = \\\n",
    "        np.round(different_records/total_expected_records*100,2)\n",
    "    print(f\"Difference percentage between DF: {difference_percentage}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of df of not matching records\n",
      "           id  age  years_on_the_job  nb_previous_loans  \\\n",
      "125   5008811   52               8.0                 27   \n",
      "125   5008811   52               8.0                 26   \n",
      "130   5008811   52               8.0                 32   \n",
      "130   5008811   52               8.0                 31   \n",
      "212   5008821   48               3.0                  1   \n",
      "...       ...  ...               ...                ...   \n",
      "2632  5008980   61               NaN                  9   \n",
      "2662  5008980   61               NaN                 39   \n",
      "2662  5008980   61               NaN                 38   \n",
      "2723  5008984   57               6.0                 26   \n",
      "2723  5008984   57               6.0                 25   \n",
      "\n",
      "      avg_amount_loans_previous  flag_own_car  status  \n",
      "125                      131.11             0       0  \n",
      "125                      130.47             0       0  \n",
      "130                      127.70             0       0  \n",
      "130                      128.85             0       0  \n",
      "212                         NaN             1       0  \n",
      "...                         ...           ...     ...  \n",
      "2632                     128.43             0       0  \n",
      "2662                     123.78             0       0  \n",
      "2662                     123.17             0       0  \n",
      "2723                     136.27             1       0  \n",
      "2723                     135.74             1       0  \n",
      "\n",
      "[100 rows x 7 columns]\n",
      "Difference percentage between DF: 6.05%\n"
     ]
    }
   ],
   "source": [
    "test_differences(df, df_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Following the hypothesis of the Age difference, we will drop this column and\n",
    "repeat the previous test of finding different records and calculate the\n",
    "differences.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "outputs": [],
   "source": [
    "df_no_head = df.drop(\"age\", axis=1)\n",
    "df_test_no_head = df_test.drop(\"age\", axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of df of not matching records\n",
      "           id  years_on_the_job  nb_previous_loans  avg_amount_loans_previous  \\\n",
      "125   5008811               8.0                 27                     131.11   \n",
      "125   5008811               8.0                 26                     130.47   \n",
      "130   5008811               8.0                 32                     127.70   \n",
      "130   5008811               8.0                 31                     128.85   \n",
      "212   5008821               3.0                  1                        NaN   \n",
      "...       ...               ...                ...                        ...   \n",
      "2632  5008980               NaN                  9                     128.43   \n",
      "2662  5008980               NaN                 39                     123.78   \n",
      "2662  5008980               NaN                 38                     123.17   \n",
      "2723  5008984               6.0                 26                     136.27   \n",
      "2723  5008984               6.0                 25                     135.74   \n",
      "\n",
      "      flag_own_car  status  \n",
      "125              0       0  \n",
      "125              0       0  \n",
      "130              0       0  \n",
      "130              0       0  \n",
      "212              1       0  \n",
      "...            ...     ...  \n",
      "2632             0       0  \n",
      "2662             0       0  \n",
      "2662             0       0  \n",
      "2723             1       0  \n",
      "2723             1       0  \n",
      "\n",
      "[100 rows x 6 columns]\n",
      "Difference percentage between DF: 3.0%\n"
     ]
    }
   ],
   "source": [
    "test_differences(df_no_head , df_test_no_head )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The difference percentage reduced dramatically, proposing the years computing\n",
    "is the causing of the differences potentially. We will remove the years on\n",
    "job field and repeat the test."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "outputs": [],
   "source": [
    "df_no_years_job= df_no_head.drop(\"years_on_the_job\", axis=1)\n",
    "df_test_no_years_job= df_test_no_head.drop(\"years_on_the_job\", axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of df of not matching records\n",
      "           id  nb_previous_loans  avg_amount_loans_previous  flag_own_car  \\\n",
      "125   5008811                 27                     131.11             0   \n",
      "125   5008811                 26                     130.47             0   \n",
      "130   5008811                 31                     128.85             0   \n",
      "130   5008811                 32                     127.70             0   \n",
      "212   5008821                  0                     100.02             1   \n",
      "...       ...                ...                        ...           ...   \n",
      "2632  5008980                  9                     128.43             0   \n",
      "2662  5008980                 39                     123.78             0   \n",
      "2662  5008980                 38                     123.17             0   \n",
      "2723  5008984                 26                     136.27             1   \n",
      "2723  5008984                 25                     135.74             1   \n",
      "\n",
      "      status  \n",
      "125        0  \n",
      "125        0  \n",
      "130        0  \n",
      "130        0  \n",
      "212        0  \n",
      "...      ...  \n",
      "2632       0  \n",
      "2662       0  \n",
      "2662       0  \n",
      "2723       0  \n",
      "2723       0  \n",
      "\n",
      "[100 rows x 5 columns]\n",
      "Difference percentage between DF: 2.08%\n"
     ]
    }
   ],
   "source": [
    "test_differences(df_no_years_job , df_test_no_years_job)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "The final differences seem to aim to a slight difference in 2% of the records\n",
    "while calculating the nb_previous_loans. As regards the percentage of\n",
    "differences between both dataframes, propagates a sligh error to the average\n",
    "loan amount.\n",
    "\n",
    "Even though further analysis could be done to explore if the nulls deal of the\n",
    "functions are the root cause of the difference, or a different cause, the\n",
    "percentage is too low and due time constraints it will be taken as an accepted\n",
    "implementation in Spark to replicate the Feature Engineering process."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
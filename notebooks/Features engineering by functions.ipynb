{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Transcript from pandas to Spark\n",
    "\n",
    "The Notebook transcripts the methods applied in pandas for the feature\n",
    "engineering generation into a Spark Dataframe and methods applied to result\n",
    "into the same, or similar outcome.\n",
    "\n",
    "At the end of the notebook the original df result will be compared with the\n",
    "spark functions outcome to compare and accept if the resulting functions are\n",
    "sufficient to accept them as a valid result."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import rank\n",
    "from pyspark.sql.functions import monotonically_increasing_id, current_date, \\\n",
    "    when, lit, col, months_between, floor\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Credit Features Processing\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw_data/dataset_credit_risk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_func = spark.read.csv(\"../data/raw_data/dataset_credit_risk.csv\",\n",
    "                         header=True,\n",
    "                         sep=',',\n",
    "                         inferSchema=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Sort and cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(by=[\"id\", \"loan_date\"])\n",
    "df = df.reset_index(drop=True)\n",
    "df[\"loan_date\"] = pd.to_datetime(df.loan_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# spark\n",
    "def order_by_id_and_loan_date(data_frame):\n",
    "    data_frame = data_frame.orderBy(\"id\", \"loan_date\")\n",
    "    # Index only to compare with pandas\n",
    "    data_frame = data_frame.withColumn(\"index\",\n",
    "                                       monotonically_increasing_id())\n",
    "    return data_frame\n",
    "\n",
    "def cast_dates_to_datetime(data_frame):\n",
    "    # loan_date\n",
    "    data_frame = data_frame.withColumn('loan_date',\n",
    "                                       data_frame['loan_date'].cast('date'))\n",
    "    data_frame = data_frame.withColumn('loan_date',\n",
    "                                       when(col(\"loan_date\")\n",
    "                                            <= current_date()+1,\n",
    "                                            col(\"loan_date\")))\n",
    "    #birthday\n",
    "    data_frame = data_frame.withColumn('birthday',\n",
    "                                       data_frame['birthday'].cast('date'))\n",
    "    data_frame = data_frame.withColumn('birthday',\n",
    "                                       when(col(\"birthday\")\n",
    "                                            <= current_date()+1,\n",
    "                                            col(\"birthday\")))\n",
    "    # job_start_date\n",
    "    data_frame = data_frame.withColumn('job_start_date',\n",
    "                                       data_frame['job_start_date'].cast('date'))\n",
    "    data_frame = data_frame.withColumn('job_start_date',\n",
    "                                       when(col(\"job_start_date\")\n",
    "                                            <= current_date()+1,\n",
    "                                            col(\"job_start_date\")))\n",
    "    return data_frame\n",
    "\n",
    "df_func = order_by_id_and_loan_date(df_func)\n",
    "df_func = cast_dates_to_datetime(df_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Feature nb_previous_loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_grouped = df.groupby(\"id\")\n",
    "df[\"nb_previous_loans\"] = df_grouped[\"loan_date\"].rank(method=\"first\") - 1\n",
    "df[\"nb_previous_loans\"] = df[\"nb_previous_loans\"].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_nb_previous_loans(data_frame):\n",
    "    window = Window.partitionBy(\"id\").orderBy(\"loan_date\")\n",
    "    data_frame = data_frame.withColumn(\"nb_previous_loans\",\n",
    "                                       rank().over(window) -1)\n",
    "    return data_frame\n",
    "df_func = generate_nb_previous_loans(df_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Feature avg_amount_loans_previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def avg_amount_loans_prev(df):\n",
    "    avg = pd.Series(index=df.index)\n",
    "    for i in df.index:\n",
    "        df_aux = df.loc[df.loan_date < df.loan_date.loc[i], :]\n",
    "        avg.at[i] = df_aux.loan_amount.mean()\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuel.rojo/.pyenv/versions/ml_technical_challenge/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/samuel.rojo/.pyenv/versions/ml_technical_challenge/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 2s, sys: 21.4 s, total: 10min 23s\n",
      "Wall time: 10min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time  \n",
    "avg_amount_loans_previous = pd.Series()\n",
    "# the following cycle is the one that takes forever if we try to compute it for the whole dataset\n",
    "for user in df.id.unique():\n",
    "    df_user = df.loc[df.id == user, :]\n",
    "    avg_amount_loans_previous = avg_amount_loans_previous.append(avg_amount_loans_prev(df_user))\n",
    "\n",
    "df[\"avg_amount_loans_previous\"] = avg_amount_loans_previous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.11 ms, sys: 5.49 ms, total: 10.6 ms\n",
      "Wall time: 152 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def generate_avg_amount_loans_previous(data_frame):\n",
    "    window = Window.partitionBy(\"id\"). \\\n",
    "        rowsBetween(Window.unboundedPreceding, -1)\n",
    "\n",
    "    data_frame = data_frame.sort(f.asc('loan_date')) \\\n",
    "        .withColumn(\"avg_amount_loans_previous\",\n",
    "                    f.mean('loan_amount').over(window))\n",
    "    return data_frame\n",
    "\n",
    "df_func = generate_avg_amount_loans_previous(df_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['birthday'] = pd.to_datetime(df['birthday'], errors='coerce')\n",
    "df['age'] = (pd.to_datetime('today').normalize() -\n",
    "             df['birthday']).dt.days // 365\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [],
   "source": [
    "def compute_age_features(data_frame):\n",
    "    data_frame = data_frame.withColumn(\"age\",\n",
    "                          floor(months_between(current_date(),\n",
    "                                               col(\"birthday\"))/lit(12))\n",
    "                          .cast('integer'))\n",
    "    return data_frame\n",
    "\n",
    "df_func = compute_age_features(df_func)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature years_on_the_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['job_start_date'] = pd.to_datetime(df['job_start_date'], errors='coerce')\n",
    "df['years_on_the_job'] = (pd.to_datetime('today').normalize() -\n",
    "                          df['job_start_date']).dt.days // 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_years_on_the_job(data_frame):\n",
    "    data_frame = data_frame.withColumn(\"years_on_the_job\",\n",
    "                          floor(months_between(current_date(),\n",
    "                                               col(\"job_start_date\"))/lit(12))\n",
    "                          .cast('integer'))\n",
    "    return data_frame\n",
    "\n",
    "df_func = compute_years_on_the_job(df_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature flag_own_car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['flag_own_car'] = df.flag_own_car.apply(lambda x : 0 if x == 'N' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_feature_own_car_flag(data_frame):\n",
    "    data_frame = data_frame.withColumn('flag_own_car',\n",
    "                                       when(col(\"flag_own_car\") == 'N',\n",
    "                                            lit(0)).otherwise(1))\n",
    "    return data_frame\n",
    "\n",
    "df_func = add_feature_own_car_flag(df_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select subset of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df[['id',\n",
    "         'age',\n",
    "         'years_on_the_job',\n",
    "         'nb_previous_loans',\n",
    "         'avg_amount_loans_previous',\n",
    "         'flag_own_car', 'status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def credit_fe_columns_subset(data_frame):\n",
    "    data_frame = data_frame.select('id',\n",
    "                             'age',\n",
    "                             'years_on_the_job',\n",
    "                             'nb_previous_loans',\n",
    "                             'avg_amount_loans_previous',\n",
    "                             'flag_own_car',\n",
    "                             'status')\n",
    "    return data_frame\n",
    "\n",
    "df_func = credit_fe_columns_subset(df_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare Results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_copy = df.copy()\n",
    "# df = df_copy.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 322,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Order both dataset to do a 1:1 comparinson"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "outputs": [],
   "source": [
    "df_func = df_func.orderBy('index') # Index only to compare with pd.Dataframe\n",
    "df = df.sort_index() # pd.Dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 80:============================>                        (109 + 12) / 200]\r"
     ]
    }
   ],
   "source": [
    "df_test = df_func.toPandas() # Transform PySpark dataframe into pd.Dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test.info(verbose=True) # PySpark convert to pandas Resulting schema"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info(verbose=True) # pd.Dataframe resulting schema"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Due to the differences presented in the schemas, the pyspark dataframe will be\n",
    "casted into the schema of the pd.Dataframe in order to reproduce the results\n",
    "and make them comparable 1:1. This is decided after seeing a comparinson\n",
    "with no nulls in both outcomes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test[\"id\"] = df_test[\"id\"].astype(int)\n",
    "df_test[\"age\"] = df_test[\"age\"].astype(int)\n",
    "df_test[\"flag_own_car\"] = df_test[\"flag_own_car\"].astype(int)\n",
    "df_test[\"nb_previous_loans\"] = df_test[\"nb_previous_loans\"].astype(int)\n",
    "df_test[\"status\"] = df_test[\"status\"].astype(int)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cast float64 fields and round to same data type and same number of decimals\n",
    "to avoid resolution misscomparison."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Round years to zero decimals\n",
    "df_test[\"years_on_the_job\"] = \\\n",
    "    df_test[\"years_on_the_job\"].astype('float64').round(0)\n",
    "df[\"years_on_the_job\"] = df[\"years_on_the_job\"].round(0)\n",
    "\n",
    "# Round float fields to 2 decimals\n",
    "df_test[\"avg_amount_loans_previous\"] = \\\n",
    "    df_test[\"avg_amount_loans_previous\"].astype('float64').round(2)\n",
    "df[\"avg_amount_loans_previous\"] = df[\"avg_amount_loans_previous\"].round(2)\n",
    "\n",
    "df_test.info(verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Assertion of a 1:1 comparison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"The outcomes are different than expected: \", df_test.equals(df))\n",
    "print(\"Are the shapes of both datasets the same?:\", (df.shape==df_test.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Because of side effects of the python floor division and traditional round\n",
    "function in the years calculated in pandas the fields with those values will\n",
    "be dropped after seing how many records have differences between both\n",
    "dataframes and adress those fields are the discrepancy causes, just to follow\n",
    "the asumption that the round vs floor libraries are the cause.\n",
    "\n",
    "Disclaimer: The floor function was denoted bevause the age of a person has to\n",
    "be quantizied after the birthday and not after 6 months or any other arbitrary\n",
    "value for the months."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def test_differences(df1, df2):\n",
    "    different_records_df=pd.concat([df1,df2]).drop_duplicates(keep=False)\n",
    "    print(\"Head of df of not matching records\")\n",
    "    print(different_records_df.sort_index().head(100))\n",
    "\n",
    "    # Both different records are kept for the same row\n",
    "    different_records = different_records_df.shape[0]/2\n",
    "    total_expected_records = df.shape[0]\n",
    "    difference_percentage = \\\n",
    "        np.round(different_records/total_expected_records*100,2)\n",
    "    print(f\"Difference percentage between DF: {difference_percentage}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_differences(df, df_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Following the hypothesis of the Age difference, we will drop this column and\n",
    "repeat the previous test of finding different records and calculate the\n",
    "differences.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_no_head = df.drop(\"age\", axis=1)\n",
    "df_test_no_head = df_test.drop(\"age\", axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_differences(df_no_head , df_test_no_head )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The difference percentage reduced dramatically, proposing the years computing\n",
    "is the causing of the differences potentially. We will remove the years on\n",
    "job field and repeat the test."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_no_years_job= df_no_head.drop(\"years_on_the_job\", axis=1)\n",
    "df_test_no_years_job= df_test_no_head.drop(\"years_on_the_job\", axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_differences(df_no_years_job , df_test_no_years_job)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "The final differences seem to aim to a slight difference in 2% of the records\n",
    "while calculating the nb_previous_loans. As regards the percentage of\n",
    "differences between both dataframes, propagates a sligh error to the average\n",
    "loan amount.\n",
    "\n",
    "Even though further analysis could be done to explore if the nulls deal of the\n",
    "functions are the root cause of the difference, or a different cause, the\n",
    "percentage is too low and due time constraints it will be taken as an accepted\n",
    "implementation in Spark to replicate the Feature Engineering process."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}